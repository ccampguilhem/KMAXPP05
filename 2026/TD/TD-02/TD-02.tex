\documentclass[11pt,a4paper]{article}

% --- Packages de base ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{geometry}
\geometry{margin=2.5cm}

% --- Mathématiques avancées ---
\usepackage{amsmath, amssymb, amsthm} % Fondamentaux pour le ML
\usepackage{bm} % Pour les vecteurs en gras : \bm{x}

% --- Graphiques et Algorithmes ---
\usepackage{graphicx}
\usepackage{booktabs} % Tableaux de qualité professionnelle
\usepackage{listings} % Pour l'insertion de code Python
\usepackage{xcolor}

% --- Mise en page spécifique TD ---
\usepackage{tcolorbox} % Pour encadrer les exercices ou notes

\title{Travaux Dirigés n°2 \\ Régression Logistique}
\author{KMAXPP05}
\date{2025-2026}

\begin{document}
	
\maketitle

\section*{Exercice 1}

On considère la fonction logistique: 

\begin{equation}
	\begin{aligned}
		&\sigma: \mathbb{R} \to ]0, 1[ \\
		&\sigma : t \mapsto \frac{1}{1 + e^{-t}}
	\end{aligned}
	\nonumber
\end{equation}

La fonction logistique est une fonction \textit{sigmoïde}. Littéralement, c'est une fonction avec une forme de \textit{S}. Mathématiquement, une fonction sigmoïde est croissante, continue et dérivable et admet deux asymptotes horizontales en $-\infty$ et $+\infty$

\begin{enumerate}
	\item Montrer que la dérivée de la fonction $\sigma(t)$ est $\sigma(t) \left(1 - \sigma(t)\right)$
	\item Montrer que $\sigma$ est strictement croissante sur $\mathbb{R}$.
	\item Montrer que $\lim_{t \rightarrow + \infty} \sigma(t) = 1$ et que $\lim_{t \rightarrow - \infty} \sigma(t) = 0$.
	\item Quelle autre fonction (trigonométrique) est également une sigmoïde ?
	\item Montrer que $\sigma$ possède la propriété suivante $\sigma(t) = 1 - \sigma(-t) \quad \forall t \in \mathbb{R}$.
	\item Déduire de la propriété précédente que $\sigma(0) = \frac{1}{2}$ et que $\sigma(t) \ge \frac{1}{2} \Longleftrightarrow t \ge 0$.
	\item Tracer approximativement la courbe de $\sigma$ sur $\mathbb{R}$.
\end{enumerate}

\section*{Exercice 2}

On cherche à construire un classifieur $C$, basé sur une régression logistique, qui prend en entrée $x \in \mathbb{R}$ et qui le classifie en la classe $0$ ou la classe $1$. Ce classifieur va être paramétré par un vecteur $\beta \in \mathcal{M}_{2,1}(\mathbb{R})$ de composantes $\beta_0$ et $\beta_1$. La classe associée sera $1$ si $C_{\beta}(x) \ge 1/2$ et $0$ sinon. Le classifieur $C$ est défini comme suit:

\begin{equation}
	\begin{aligned}
		C_{\beta}(x) &= \sigma \left(\beta_0 + \beta_1 \, x\right) \\
		             &= \frac{1}{ 1 + \exp{\left(- \beta_0 - \beta_1 \, x\right)}}
	\end{aligned}
	\nonumber
\end{equation}

Les réponses de l'exercice 1 peuvent être utilisées pour les questions de cet exercice.

\begin{enumerate}
	\item Pour $\beta = \begin{pmatrix}0 \\ 1\end{pmatrix}$ quels $x$ sont classés en $0$ et quels $x$ sont classés en $1$ ?
	\item Même question pour $\beta = \begin{pmatrix}1 \\ -1\end{pmatrix}$
	\item Pour un $x \ne 0$ et $\beta_0$ fixés, lorsque $\beta_1$ devient assez grand ($\beta_1 \to + \infty$), comment est classé $x$ ? Même question lorsque $\beta_1 \to -\infty$.
\end{enumerate}

\section*{Exercice 3}

Nous disposons des données $\mathcal{D}$ suivantes pour des joueurs de rugby. L'espace des caractéristiques d'entrée est défini par le poids $x$ et noté $\mathcal{X} \subseteq \mathbb{R}$. L'espace des caractéristiques de sortie est défini par la position $y$ noté $\mathcal{Y} = \{0, 1\}$:

\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		\textbf{Poids} (kg) & \textbf{Position} \\ \hline
		112 &  avant = 1       \\
		85  &  trois-quart = 0 \\
		135 &  avant = 1       \\
		92  &  trois-quart = 0 \\
		\hline
	\end{tabular}
\end{center}

On suppose que les $n = 4$ observations sont indépendantes. Nous cherchons à établir un classifieur basé sur un modèle de régression logistique de la forme suivante, avec $\beta_0 \in \mathbb{R}$ et $\beta_1 \in \mathbb{R}$:

\begin{equation}
	C_{\beta}(x) = 
	\begin{cases}
		0 \quad \forall x \quad  \displaystyle \frac{1}{1 + \exp{\left(- \beta_0 - \beta_1 \, x\right)}} < \frac{1}{2} \\[10pt]
		1 \quad \forall x \quad  \displaystyle \frac{1}{1 + \exp{\left(- \beta_0 - \beta_1 \, x\right)}} \ge \frac{1}{2}
	\end{cases}
	\nonumber
\end{equation}

On note $\beta \in \mathcal{M}_{2,1}(\mathbb{R})$ le vecteur:

\begin{equation}
	\beta = \begin{pmatrix}\beta_0 \\ \beta_1\end{pmatrix}
	\nonumber
\end{equation}

On associe à chaque observation $i$ une variable aléatoire $Y^{(i)}$ suivant une loi de Bernoulli de paramètre $p^{(i)} = \sigma(\tilde{x}^{(i)} \beta)$:

\begin{equation}
	\begin{cases}
		P(Y^{(i)} = 1) = p^{(i)} \\
		P(Y^{(i)} = 0) = 1 - p^{(i)}
	\end{cases}
	\nonumber
\end{equation}

Les réponses de l'exercice 1 peuvent être utilisées pour les questions de cet exercice.

\begin{enumerate}
	\item Quelle application $\Phi: \mathcal{X} \to \tilde{\mathcal{X}} \subseteq \mathbb{R}^2$ permet-elle de calculer la probabilité pour l'observation $i$ sous la forme $\sigma(\tilde{x}^{(i)} \beta)$ où $\sigma$ est la fonction logistique. Quelle est la matrice de design $\tilde{X}$ pour ce problème de classification ?
	\item Vérifier que la probabilité de la loi de Bernoulli pour la variable aléatoire $Y^{(i)}$ peut s'écrire $P(Y^{(i)} = y^{(i)}) = \left( p^{(i)} \right)^{y^{(i)}} \left(1 - p^{(i)}\right)^{\left(1 - y^{(i)}\right)}$
	\item Pour une valeur fixe de $\beta$, quelle est la vraisemblance sur $\mathcal{D}$ selon les variables aléatoires de Bernoulli introduites ci-dessus ?
	\item Calculer la log-vraisemblance négative moyenne sur $\mathcal{D}$. Sous quelle autre dénomination usuelle cette quantité est-elle aussi connue ?
	\item Quelle condition doit satisfaire $\hat{\beta}$ pour être la meilleure estimation de ce problème de régression logistique ?
	\item On rappelle que $\tilde{x}^{(i)}$ est le vecteur ligne de l'observation $i$ dans l'espace augmenté $\tilde{\mathcal{X}}$. On pose ${t^{(i)} = \tilde{x}^{(i)} \beta = \beta_0 + \beta_1 x^{(i)}}$. Démontrer que $\displaystyle \frac{d t^{(i)}}{d\beta} = \tilde{x}^{(i)T}$
	\item Démontrer que $\displaystyle \frac{d}{d t^{(i)}}  \ln{\left[\sigma\left(t^{(i)}\right)\right]} = 1 - \sigma\left(t^{(i)}\right)$. 
	\item En déduire que $\displaystyle \frac{d}{d \beta}  \ln{\left[\sigma\left(\tilde{x}^{(i)} \beta\right)\right]} = \left[1 - \sigma\left(\tilde{x}^{(i)} \beta\right) \right] \tilde{x}^{(i)T}$
	\item Démontrer que $\displaystyle \frac{d}{d t^{(i)}}  \ln{\left[1 - \sigma\left(t^{(i)}\right)\right]} = - \sigma\left(t^{(i)}\right)$
	\item En déduire que $\displaystyle \frac{d}{d \beta}  \ln{\left[1 - \sigma\left(\tilde{x}^{(i)} \beta\right)\right]} = - \sigma\left(\tilde{x}^{(i)} \beta\right) \tilde{x}^{(i)T}$	
	\item Démontrer que le gradient de la log-vraisemblance négative moyenne par rapport à $\beta$ est égal à $\displaystyle -\frac{1}{n} \sum_{i=1}^n \left( y^{(i)} - \sigma(\tilde{x}^{(i)} \beta)\right) \tilde{x}^{(i)T}$.
	\item Démontrer que ce même gradient peut s'écrire sous la forme suivant: $\displaystyle -\frac{1}{n} \tilde{X}^T \left( Y - \sigma(\tilde{X} \beta)\right)$
	\item On fixe $\beta = \begin{pmatrix}-90 \\ 1\end{pmatrix}$. On pourrait calculer que le gradient de la log-vraisemblance négative moyenne est à peu près égal à $\begin{pmatrix}0,22 \\ 20,4\end{pmatrix}$. Qu'en déduire de cette valeur de $\beta$ ?
	\item En gardant la même valeur de $\beta$, quel est le poids à partir duquel le classifieur va prédire une classe $1$ ? En gardant $\beta_1 = 1$, quelle serait une meilleure alternative pour $\beta_0$ afin d'obtenir un meilleur classifieur ?
\end{enumerate}
	
\end{document}